# Selected Publications 
<!-- 注意加入图片的格式，前面是一定要有/的！ -->

<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> TPAMI 2026 </div> -->
        <img src='/images/article/figure16.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Decoupled Hierarchical Distillation for Multimodal Emotion Recognition**

**Yong Li**, Yuanzhi Wang, Yi Ding, Shiqing Zhang, Ke Lu, Cuntai Guan

*IEEE Transactions on Pattern Analysis and Machine Intelligence(**TPAMI**), (**2026**).*

[\[PDF\]](https://ieeexplore.ieee.org/document/11370718)

</div>
</div>


<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> TPAMI 2020 </div> -->
        <img src='/images/article/figure14.png' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Instance-Consistent Fair Face Recognition**

**Yong Li**, Yufei Sun, Zhen Cui, Pengcheng Shen, Shiguang Shan

*IEEE Transactions on Pattern Analysis and Machine Intelligence(**TPAMI**), (**2025**).*

[\[PDF\]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10904287)

</div>
</div>


<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> TPAMI 2020 </div> -->
        <img src='/images/article/learning.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Learning Representations for Facial Actions from Unlabeled Videos**

**Yong Li**, Jiabei Zeng, Shiguang Shan

*IEEE Transactions on Pattern Analysis and Machine Intelligence (**TPAMI**), (**2022**).*

[\[PDF\]](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9145674)

</div>
</div>


<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> 2026 </div> -->
        <img src='/images/article/DreamActor_M2.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**DreamActor-M2: Universal Character Image Animation via Spatiotemporal In-Context Learning**

Mingshuang Luo, Shuang Liang, Zhengkun Rong, Yuxuan Luo, Tianshu Hu, Ruibing Hou, Hong Chang, **Yong Li**, Yuan Zhang, Mingyuan Gao

*arXiv preprint arXiv:2601.21716, (**2026**), Cooperate with ByteDance*

[\[PDF\]](https://arxiv.org/abs/2601.21716)

</div>
</div>




<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> IEEE 2025 </div> -->
        <img src='/images/article/Decoupled Doubly Contrastive Learning for Cross Domain Facial Action Unit Detection.png' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Decoupled Doubly Contrastive Learning for Cross Domain Facial Action Unit Detection**

**Yong Li**, Menglin Liu, Zhen Cui, Yi Ding, Yuan Zong, Wenming Zheng, Shiguang Shan, Cuntai Guan

*IEEE Transactions on Image Processing (**TIP**), (**2025**).*

[\[PDF\]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10914502)

</div>
</div>











<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> TAC 2024 </div> -->
        <img src='/images/article/tac2024.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Beyond Overfitting: Doubly Adaptive Dropout for Generalizable AU Detection**

**Yong Li**, Yi Ren, Xuesong Niu, Yi Ding, Xiu-Shen Wei, Cuntai Guan

*IEEE Transactions on Affective Computing (**TAC**), (**2025**).*

[\[PDF\]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10904329)
</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> TAC 2024 </div> -->
        <img src='/images/article/learning-IR.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Learning Attribute-Aware Hash Codes for Fine-Grained Image Retrieval via Query Optimization**

Peng Wang, **Yong Li**, Lin Zhao, Xiu-Shen Wei

*International Conference on Machine Learning (**ICML**), (**2025**).*

[\[PDF\]](https://openreview.net/pdf?id=rn3thNKvzw)
</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> TAC 2024 </div> -->
        <img src='/images/article/eeg-deformer.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**EEG-Deformer: A Dense Convolutional Transformer for Brain-computer Interfaces**

Yi Ding#, **Yong Li#**, Hao Sun, Rui Liu, Chengxuan Tong, Chenyu Liu, Xinliang Zhou, Cuntai Guan

*IEEE Journal of Biomedical and Health Informatics (**J-BHI**), (**2024**).*

[\[PDF\]](https://ieeexplore.ieee.org/document/10763464)
</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> PR 2024 </div> -->
        <img src='/images/article/pr2024.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Collaborative Contrastive Learning for Cross-Domain Gaze Estimation**

Lifan Xia, **Yong Li\***, Xin Cai, Zhen Cui, Chunyan Xu, Antoni B. Chan

*Pattern Recognition (**PR**), (**2024**).*

[\[PDF\]](https://www.sciencedirect.com/science/article/pii/S0031320324009956?via%3Dihub)
</div>
</div>






<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='/images/article/decoupled.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Decoupled Multimodal Distilling for Emotion Recognition**

**Yong Li**, Yuanzhi Wang, Zhen Cui

*Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (**CVPR**), (**2023**) **<span style="color:red">(Highlight)</span>**.*

[\[PDF\]](https://arxiv.org/abs/2303.13802)
[\[Code\]](https://github.com/mdswyz/DMD)

</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='/images/article/figure15.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Incomplete multimodality-diffused emotion recognition**

Yuanzhi Wang, **Yong Li**\*, Zhen Cui\*

*Neural Information Processing Systems (**NeurIPS**), (**2023**).*

[\[PDF\]](https://proceedings.neurips.cc/paper_files/paper/2023/file/372cb7805eaccb2b7eed641271a30eec-Paper-Conference.pdf)
[\[Code\]](https://github.com/mdswyz/IMDer)

</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='/images/article/distribution.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Distribution-Consistent Modal Recovering for Incomplete Multimodal Learning**

Yuanzhi Wang, Zhen Cui\*, **Yong Li**\*

*Proceedings of the IEEE Conference on International Conference on Computer Vision (**ICCV**), (**2023**).*

[\[PDF\]](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Distribution-Consistent_Modal_Recovering_for_Incomplete_Multimodal_Learning_ICCV_2023_paper.pdf)
[\[Code\]](https://github.com/mdswyz/DiCMoR)

</div>
</div>



<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='/images/article/figure4.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Contrastive Learning of Person-independent Representations for Facial Action Unit Detection**

**Yong Li**, Shiguang Shan

*IEEE Transactions on Image Processing (**TIP**), (**2023**).*

[\[PDF\]](https://arxiv.org/pdf/2403.03400)

</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='/images/article/figure5.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Graph Jigsaw Learning for Cartoon Face Recognition**

**Yong Li**, Lingjie Lao, Zhen Cui, Shiguang Shan, Jian Yang

*IEEE Transactions on Image Processing (**TIP**), (**2023**).*

[\[PDF\]](https://arxiv.org/abs/2107.06532)
[\[Code\]](https://github.com/mysee1989/GraphJigsaw)

</div>
</div>






<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='/images/article/figure6.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**3D3M: 3D Modulated Morphable Model for Monocular Face Reconstruction**

**Yong Li**, Qiang Hao, Jianguo Hu, Xinmiao Pan, Zechao Li, Zhen Cui

*IEEE Transactions on Multimedia (**TMM**), (**2022**).*

[\[PDF\]](https://ieeexplore.ieee.org/document/9913696/)

</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='/images/article/figure8.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Meta Auxiliary Learning for Facial Action Unit Detection**

**Yong Li**, Shiguang Shan

*IEEE Transactions on Affective Computing (**TAC**), (**2021**).*

[\[PDF\]](https://arxiv.org/abs/2105.06620)

</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='/images/article/figure9.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Self-supervised representation learning from videos for facial action unit detection**

**Yong Li**, Jiabei Zeng, Shiguang Shan, Xilin Chen

*Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition(**CVPR**), (**2019**) **<span style="color:red">(Oral)</span>**.*

[\[PDF\]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Self-Supervised_Representation_Learning_From_Videos_for_Facial_Action_Unit_Detection_CVPR_2019_paper.pdf)
[\[Code\]](https://github.com/mysee1989/TCAE)

</div>
</div>


<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='/images/article/figure10.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Occlusion aware facial expression recognition using cnn with attention mechanism**

**Yong Li**, Jiabei Zeng, Shiguang Shan, Xilin Chen

*IEEE Transactions on Image Processing 28 (5), 2439-2450 (**TIP**), (**2020**).*

[\[PDF\]](https://ieeexplore.ieee.org/document/8576656)
[\[Code\]](https://github.com/mysee1989/PG-CNN)

</div>
</div>






<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='/images/article/figure13.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Context-dependent emotion recognition**

Zili Wang, Lingjie Lao, Xiaoya Zhang, **Yong Li***, Tong Zhang, Zhen Cui

***<span style="color:red">(Best poster in ChinaMM (2022))</span>.***

[\[PDF\]](https://www.sciencedirect.com/science/article/pii/S1047320322001997)

</div>
</div>
