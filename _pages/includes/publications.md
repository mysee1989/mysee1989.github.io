# Selected Publications 

<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> TPAMI 2020 </div> -->
        <img src='images/article/learning.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Learning Representations for Facial Actions from Unlabeled Videos**

**Yong Li**, Jiabei Zeng, Shiguang Shan

*IEEE Transactions on Pattern Analysis and Machine Intelligence(**TPAMI**), 2022.*

[\[PDF\]](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9145674)

</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> TPAMI 2020 </div> -->
        <img src='images/article/figure14.png' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Instance-Consistent Fair Face Recognition**

**Yong Li**, Yufei Sun, Zhen Cui, Pengcheng Shen, Shiguang Shan

*IEEE Transactions on Pattern Analysis and Machine Intelligence(**TPAMI**), accepted.*

</div>
</div>









<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> PR 2024 </div> -->
        <img src='images/article/PR_xlf.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Collaborative Contrastive Learning for Cross-Domain Gaze Estimation**

Lifan Xia, **Yong Lia**, Xin Cai, Zhen Cui, Chunyan Xu, Antoni B. Chan

*Pattern Recognition(**PR**), 2024.*

</div>
</div>






<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='images/article/decoupled.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Decoupled Multimodal Distilling for Emotion Recognition**

**Yong Li**, Yuanzhi Wang, Zhen Cui

*Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition(**CVPR**), 2023 **<span style="color:red">(Highlight)</span>**.*

[\[PDF\]](https://arxiv.org/abs/2303.13802)
[\[Code\]](https://github.com/mdswyz/DMD)

</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='images/article/figure15.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Incomplete multimodality-diffused emotion recognition**

Yuanzhi Wang, **Yong Li**\*, Zhen Cui\*

*Neural Information Processing Systems(**NeurIPS**), 2023.*

[\[PDF\]](https://proceedings.neurips.cc/paper_files/paper/2023/file/372cb7805eaccb2b7eed641271a30eec-Paper-Conference.pdf)
[\[Code\]](https://github.com/mdswyz/IMDer)

</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='images/article/distribution.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Distribution-Consistent Modal Recovering for Incomplete Multimodal Learning**

Yuanzhi Wang, Zhen Cui\*, **Yong Li**\*

*Proceedings of the IEEE Conference on International Conference on Computer Vision(**ICCV**), 2023.*

[\[PDF\]](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Distribution-Consistent_Modal_Recovering_for_Incomplete_Multimodal_Learning_ICCV_2023_paper.pdf)
[\[Code\]](https://github.com/mdswyz/DiCMoR)

</div>
</div>



<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='images/article/figure4.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Contrastive Learning of Person-independent Representations for Facial Action Unit Detection**

**Yong Li**, Shiguang Shan

*IEEE Transactions on Image Processing (**TIP**), 2023.*

[\[PDF\]](https://arxiv.org/pdf/2403.03400)

</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='images/article/figure5.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Graph Jigsaw Learning for Cartoon Face Recognition**

**Yong Li**, Lingjie Lao, Zhen Cui, Shiguang Shan, Jian Yang

*IEEE Transactions on Image Processing (**TIP**), 2022.*

[\[PDF\]](https://arxiv.org/abs/2107.06532)
[\[Code\]](https://github.com/mysee1989/GraphJigsaw)

</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='images/article/figure6.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**3D3M: 3D Modulated Morphable Model for Monocular Face Reconstruction**

**Yong Li**, Qiang Hao, Jianguo Hu, Xinmiao Pan, Zechao Li, Zhen Cui

*IEEE Transactions on Multimedia (TMM), 2022.*

[\[PDF\]](https://ieeexplore.ieee.org/document/9913696/)

</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='images/article/figure7.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Learning Fair Face Representation With Progressive Cross Transformer**

**Yong Li**, Lingjie Lao, Zhen Cui, Shiguang Shan, Jian Yang

*Arxiv 2021, under review.*

[\[PDF\]](https://arxiv.org/abs/2108.04983)

</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='images/article/figure8.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Meta Auxiliary Learning for Facial Action Unit Detection**

**Yong Li**, Shiguang Shan

*IEEE Transactions on Affective Computing (TAC), 2021.*

[\[PDF\]](https://arxiv.org/abs/2105.06620)

</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='images/article/figure9.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Self-supervised representation learning from videos for facial action unit detection**

**Yong Li**, Jiabei Zeng, Shiguang Shan, Xilin Chen

*Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition(**CVPR**), 2019 **<span style="color:red">(Oral)</span>**.*

[\[PDF\]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Self-Supervised_Representation_Learning_From_Videos_for_Facial_Action_Unit_Detection_CVPR_2019_paper.pdf)
[\[Code\]](https://github.com/mysee1989/TCAE)

</div>
</div>


<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='images/article/figure10.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Occlusion aware facial expression recognition using cnn with attention mechanism**

**Yong Li**, Jiabei Zeng, Shiguang Shan, Xilin Chen

*IEEE Transactions on Image Processing 28 (5), 2439-2450 (**TIP**), 2020.*

[\[PDF\]](https://ieeexplore.ieee.org/document/8576656)
[\[Code\]](https://github.com/mysee1989/PG-CNN)

</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='images/article/figure11.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Patch-gated cnn for occlusion-aware facial expression recognition**

**Yong Li**, Jiabei Zeng, Shiguang Shan, Xilin Chen

*International Conference on Pattern Recognition (**ICPR**), 2018 **<span style="color:red">(Oral)</span>**.*

[\[PDF\]](http://www.jdl.link/doc/2011/201911019432863571_2018092516364248.pdf)
[\[Code\]](https://github.com/mysee1989/PG-CNN)

</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='images/article/figure12.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Kinnet: Fine-to-coarse deep metric learning for kinship verification**

**Yong Li**, Jiabei Zeng, Jie Zhang, Anbo Dai, Meina Kan, Shiguang Shan, Xilin Chen

*Proceedings of the 2017 Workshop on Recognizing Families In the Wild,13-20 **<span style="color:red">(keynote)</span>**.*

[\[PDF\]](https://dl.acm.org/doi/10.1145/3134421.3134425)

</div>
</div>





<div class='paper-box'>
    
<div class='paper-box-image'>
    <div>
        <!-- <div class="badge"> CVPR 2016 </div> -->
        <img src='images/article/figure13.jpg' alt="sym" width="100%">
    </div>
</div>

<div class='paper-box-text' markdown="1">

**Context-dependent emotion recognition**

Zili Wang, Lingjie Lao, Xiaoya Zhang, **Yong Li***, Tong Zhang, Zhen Cui

***<span style="color:red">(Best poster in ChinaMM 2022)</span>.***

[\[PDF\]](https://www.sciencedirect.com/science/article/pii/S1047320322001997)

</div>
</div>
